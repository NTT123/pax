{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "\n",
    "from pretrained_resnet18 import (IMAGENET_MEAN, IMAGENET_STD,\n",
    "                                 load_pretrained_resnet18)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "resnet18 = load_pretrained_resnet18()\n",
    "resnet18_pt = torchvision.models.resnet18(pretrained=True).eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test_resnet(resnet18, resnet18_pt):\n",
    "    \"\"\"check if the predicted logits of the two networks on random inputs are the same.\"\"\"\n",
    "    img = jax.random.normal(jax.random.PRNGKey(11), (16, 3, 224, 224))\n",
    "    a = resnet18_pt(torch.from_numpy(np.copy(jax.device_get(img)))).data.numpy()\n",
    "\n",
    "    b = jax.device_get(resnet18(img))\n",
    "    assert jnp.max(jnp.abs(b - a)).item() < 1e-5\n",
    "\n",
    "\n",
    "test_resnet(resnet18, resnet18_pt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test_real_image_prediction(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content)).resize([350, 224])\n",
    "    img = img.resize((224, 224))\n",
    "    img224 = np.array(img).astype(np.float32) / 255.0\n",
    "    img224 = (img224 - IMAGENET_MEAN[None, None, :]) / IMAGENET_STD[None, None, :]\n",
    "    img224 = jnp.transpose(img224, axes=(2, 0, 1))[None]\n",
    "    labels = (\n",
    "        requests.get(\n",
    "            \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "        )\n",
    "        .content.decode(\"utf-8\")\n",
    "        .split(\"\\n\")\n",
    "    )\n",
    "    logits = resnet18(img224)\n",
    "    predicted_label = labels[jnp.argmax(logits, axis=-1).item()]\n",
    "    logits_pt = resnet18_pt(torch.from_numpy(np.copy(img224)))\n",
    "    assert jnp.max(jnp.abs(logits - logits_pt.data.numpy())) < 1e-5\n",
    "    ImageDraw.Draw(img).text(\n",
    "        (10, 0),\n",
    "        predicted_label,\n",
    "        (255, 0, 0),\n",
    "    )\n",
    "    return img\n",
    "\n",
    "\n",
    "test_real_image_prediction(\n",
    "    \"https://static.scientificamerican.com/sciam/cache/file/381CAC9C-0218-4E87-A9495AB3B0057912_source.png?w=590&h=800&C58484F3-9096-4905-98A3DF50A97807CF\"\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}