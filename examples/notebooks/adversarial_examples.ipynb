{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WK9FrSvGQ5Wn"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from io import BytesIO\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pax\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "from pretrained_resnet18 import IMAGENET_MEAN, IMAGENET_STD, load_pretrained_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weMgQe5AcH3e"
   },
   "outputs": [],
   "source": [
    "pax.seed_rng_key(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfcQP_0wNnRL"
   },
   "outputs": [],
   "source": [
    "def prepare_image(img):\n",
    "    \"\"\"Normalize the image to the data distribution in which the model is trained.\"\"\"\n",
    "    img224 = img.astype(np.float32) / 255.0\n",
    "    img224 = (img224 - IMAGENET_MEAN) / IMAGENET_STD\n",
    "    img224 = jnp.transpose(img224, axes=(0, 3, 1, 2))\n",
    "    return img224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5gz7q0wRHol"
   },
   "outputs": [],
   "source": [
    "# download the ground truth labels\n",
    "LABELS = (\n",
    "    requests.get(\n",
    "        \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "    )\n",
    "    .content.decode(\"utf-8\")\n",
    "    .split(\"\\n\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ie1mjydKXXYs"
   },
   "outputs": [],
   "source": [
    "def prediction(net, img):\n",
    "    \"\"\"make a prediction.\"\"\"\n",
    "    img224 = prepare_image(img)\n",
    "    logits = net.eval()(img224)\n",
    "    index = jnp.argmax(logits, axis=-1).item()\n",
    "    predicted_label = LABELS[index]\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVzNtA9BRC2e"
   },
   "outputs": [],
   "source": [
    "resnet18 = load_pretrained_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4FdjjnoXYk0"
   },
   "outputs": [],
   "source": [
    "# download an image of a cat from the Internet.\n",
    "URL = \"https://i.natgeofe.com/n/3861de2a-04e6-45fd-aec8-02e7809f9d4e/02-cat-training-NationalGeographic_1484324_square.jpg\"\n",
    "response = requests.get(URL)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img = img.resize((224, 224))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HYGqhRScwtV"
   },
   "outputs": [],
   "source": [
    "# check if the model is working correctly.\n",
    "input_image = np.array(img)[None].astype(np.float32)\n",
    "predicted_label = prediction(resnet18, input_image)\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zdCfiQtNPaT"
   },
   "outputs": [],
   "source": [
    "def loss_fn(net, image, label):\n",
    "    \"\"\"a standard loss function\"\"\"\n",
    "    image = prepare_image(image)\n",
    "    logits = net.eval()(image)\n",
    "    llh = jax.nn.log_softmax(logits, axis=-1)\n",
    "    target = jax.nn.one_hot(label, num_classes=llh.shape[-1])\n",
    "    llh = jnp.sum(target * llh, axis=-1)\n",
    "    loss = -jnp.mean(llh)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saoh4A6vRMJV"
   },
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=\"epsilon\")\n",
    "def adversarial_step(net, image, label, original_image, epsilon=1.0):\n",
    "    # compute the gradient w.r.t. the image\n",
    "    loss, grads = jax.value_and_grad(loss_fn, argnums=1)(net, image, label)\n",
    "\n",
    "    # projected gradient descent\n",
    "    image = image - jnp.sign(grads) * 1e-3\n",
    "    image = original_image + jnp.clip(\n",
    "        image - original_image, a_min=-epsilon, a_max=epsilon\n",
    "    )\n",
    "    image = jnp.clip(image, a_min=0.0, a_max=255.0)\n",
    "    return image, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcwaNO6kOUpr"
   },
   "outputs": [],
   "source": [
    "new_label = \"African elephant\"\n",
    "adversarial_label = jnp.array([LABELS.index(new_label)])\n",
    "adversarial_image = input_image\n",
    "epsilon = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSAp1Q3zQXWT"
   },
   "outputs": [],
   "source": [
    "for step in range(100_000):\n",
    "    adversarial_image, loss = adversarial_step(\n",
    "        resnet18,\n",
    "        adversarial_image,\n",
    "        adversarial_label,\n",
    "        input_image,\n",
    "        epsilon=epsilon,\n",
    "    )\n",
    "    if step % 100 == 0:\n",
    "        label = prediction(resnet18, adversarial_image.astype(jnp.uint8))\n",
    "        print(f\"step {step:4d}  loss {loss:6.3f}  ->  {label}\")\n",
    "        if label == new_label:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTUxQXmifZzs"
   },
   "outputs": [],
   "source": [
    "# sanity check with a real image of an african elephant\n",
    "elephant_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/African_Elephant_%28Loxodonta_africana%29_male_%2817289351322%29.jpg/1200px-African_Elephant_%28Loxodonta_africana%29_male_%2817289351322%29.jpg\"\n",
    "response = requests.get(elephant_url)\n",
    "elephant_img = Image.open(BytesIO(response.content))\n",
    "elephant_img = elephant_img.resize((224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6M4fXfXQ0jM"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(14, 3))\n",
    "ax[0].imshow(input_image[0].astype(jnp.uint8))\n",
    "ax[1].imshow(adversarial_image[0].astype(jnp.uint8))\n",
    "diff = jnp.max(jnp.abs(adversarial_image - input_image), axis=-1)\n",
    "diff_img = ax[2].imshow(diff[0])\n",
    "fig.colorbar(diff_img, ax=ax[2])\n",
    "ax[3].imshow(elephant_img)\n",
    "\n",
    "label0 = prediction(resnet18, input_image.astype(jnp.uint8))\n",
    "label1 = prediction(resnet18, adversarial_image.astype(jnp.uint8))\n",
    "label3 = prediction(resnet18, np.array(elephant_img)[None].astype(np.float32))\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].axis(\"off\")\n",
    "\n",
    "ax[0].set_title(label0)\n",
    "ax[1].set_title(label1)\n",
    "ax[2].set_title(\"Difference\")\n",
    "ax[3].set_title(label3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Adversarial examples.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
