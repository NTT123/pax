{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO8FzYhDrLdF"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/ntt123/pax/blob/main/examples/notebooks/VAE.ipynb\" target=\"_top\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"vertical-align:text-bottom\"></a>\n",
    "\n",
    "This is an example notebook showing how to train and test a Variational AutoEncoder (VAE).\n",
    "\n",
    "It closely follows Keras VAE example at \n",
    "https://keras.io/examples/generative/vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wemh2QNsAdE"
   },
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jWlZeJQ_aUEl"
   },
   "outputs": [],
   "source": [
    "# uncomment to install PAX\n",
    "# !pip3 install -q git+https://github.com/NTT123/pax.git#egg=pax[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dv5lSsqSaaik"
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import opax\n",
    "import pax\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "### config ###\n",
    "batch_size = 128\n",
    "vae_dim = 2\n",
    "learning_rate = 1e-3\n",
    "pax.seed_rng_key(42)\n",
    "\n",
    "\n",
    "class LossInfo(NamedTuple):\n",
    "    # A record of training losses.\n",
    "    loss: jnp.ndarray\n",
    "    reconstruction_loss: jnp.ndarray\n",
    "    kl_loss: jnp.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gWk3iKCsElE"
   },
   "source": [
    "## Convolutional VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGqdo_yMhXjp"
   },
   "outputs": [],
   "source": [
    "# use `leaky_relu` instead of `relu` for better gradient signals.\n",
    "from functools import partial\n",
    "\n",
    "leaky_relu = partial(jax.nn.leaky_relu, negative_slope=0.1)\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(pax.Module):\n",
    "    def __init__(self, latent_dim: int):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = pax.nn.Sequential(\n",
    "            pax.nn.Conv2D(1, 32, 3, (2, 2), padding=\"SAME\"),\n",
    "            leaky_relu,\n",
    "            pax.nn.Conv2D(32, 64, 3, (2, 2), padding=\"SAME\"),\n",
    "            leaky_relu,\n",
    "            lambda x: jnp.reshape(x, (x.shape[0], -1)),\n",
    "            pax.nn.Linear(3136, 16),\n",
    "            leaky_relu,\n",
    "            pax.nn.Linear(16, 2 * latent_dim),\n",
    "        )\n",
    "\n",
    "        self.decoder = pax.nn.Sequential(\n",
    "            pax.nn.Linear(latent_dim, 7 * 7 * 32),\n",
    "            leaky_relu,\n",
    "            lambda x: jnp.reshape(x, (x.shape[0], 7, 7, 32)),\n",
    "            pax.nn.Conv2DTranspose(32, 64, 3, 2, padding=\"SAME\"),\n",
    "            leaky_relu,\n",
    "            pax.nn.Conv2DTranspose(64, 32, 3, 2, padding=\"SAME\"),\n",
    "            leaky_relu,\n",
    "            pax.nn.Conv2DTranspose(32, 1, 3, 1, padding=\"SAME\"),\n",
    "        )\n",
    "        # register an internal random key.\n",
    "        self.register_state(\"rng_key\", pax.next_rng_key())\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.encoder(x)\n",
    "        vae_mean, vae_logvar = jnp.split(x, 2, axis=-1)\n",
    "        if self.training:\n",
    "            # refresh the internal random key.\n",
    "            self.rng_key, rng_key = jax.random.split(self.rng_key)\n",
    "        else:\n",
    "            rng_key = self.rng_key\n",
    "        noise = jax.random.normal(rng_key, shape=vae_mean.shape, dtype=vae_mean.dtype)\n",
    "        x = noise * jnp.exp(0.5 * vae_logvar) + vae_mean\n",
    "        x = self.decoder(x)\n",
    "        return x, vae_mean, vae_logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwqPTlCOsLi8"
   },
   "source": [
    "## Loss function\n",
    "\n",
    "The loss function is the sum of the ``reconstruction`` loss and the ``kl-divergence`` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhdbfcA_HT3Y"
   },
   "outputs": [],
   "source": [
    "def sigmoid_binary_cross_entropy(logits, targets):\n",
    "    ls = jax.nn.log_sigmoid\n",
    "    return -ls(logits) * targets - ls(-logits) * (1.0 - targets)\n",
    "\n",
    "\n",
    "@pax.pure\n",
    "def loss_fn(model: VariationalAutoEncoder, inputs):\n",
    "    output, vae_mean, vae_logvar = model(inputs)\n",
    "    N = inputs.shape[0]  # batch size\n",
    "    reconstruction_loss = jnp.sum(sigmoid_binary_cross_entropy(output, inputs))\n",
    "    reconstruction_loss = reconstruction_loss / N\n",
    "    kl_loss = jnp.sum(\n",
    "        -0.5 * (1 + vae_logvar - jnp.square(vae_mean) - jnp.exp(vae_logvar))\n",
    "    )\n",
    "    kl_loss = kl_loss / N\n",
    "    loss = reconstruction_loss + kl_loss\n",
    "    return loss, (LossInfo(loss, reconstruction_loss, kl_loss), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_4rbWPbsVO0"
   },
   "source": [
    "## Tensorflow Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JREXiEp4sKy7"
   },
   "outputs": [],
   "source": [
    "def load_dataset(with_label=False):\n",
    "    \"\"\"Return a tensorflow dataset.\n",
    "\n",
    "    Arguments:\n",
    "        with_label: bool, return `(data, label)`.\n",
    "\n",
    "    \"\"\"\n",
    "    ds = tfds.load(\"mnist:3.*.*\")\n",
    "    ds = ds[\"train\"].concatenate(ds[\"test\"])\n",
    "    ds = (\n",
    "        ds.map(lambda x: (tf.cast(x[\"image\"], tf.float32) / 255.0, x[\"label\"]))\n",
    "        .map((lambda x, y: (x, y)) if with_label else (lambda x_, y_: x_))\n",
    "        .cache()\n",
    "        .shuffle(len(ds))  # shuffle the whole dataset\n",
    "    )\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-WQWCcUsXS7"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RlWhgDwphizZ",
    "outputId": "8e3e4fcc-408f-4cb3-f399-36156a32f3be"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    vae = VariationalAutoEncoder(vae_dim)\n",
    "    print(f\"===== VAE MODEL =====\\n{vae.summary()}\\n\\n\")\n",
    "    optimizer = opax.adam(learning_rate, eps=1e-7)(vae.parameters())\n",
    "\n",
    "    train_data = load_dataset(with_label=False).batch(batch_size, drop_remainder=True)\n",
    "    fast_update_fn = jax.jit(pax.utils.build_update_fn(loss_fn))\n",
    "\n",
    "    training_losses = []\n",
    "    for epoch in range(50):\n",
    "        losses = LossInfo(0.0, 0.0, 0.0)\n",
    "        for batch in train_data:\n",
    "            batch = jax.tree_map(lambda x: x.numpy(), batch)\n",
    "            vae, optimizer, loss_info = fast_update_fn(vae, optimizer, batch)\n",
    "            training_losses.append(loss_info.loss)\n",
    "            losses = jax.tree_map(lambda x, y: x + y, losses, loss_info)\n",
    "\n",
    "        losses = jax.tree_map(lambda x: x / len(train_data), losses)\n",
    "        print(\n",
    "            f\"[Epoch {epoch:>2}]  train loss {losses.loss:.3f}  reconstruction loss {losses.reconstruction_loss:.3f}  kl_loss {losses.kl_loss:.3f}\"\n",
    "        )\n",
    "\n",
    "    plt.plot(training_losses)\n",
    "    plt.grid(\"on\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.title(\"Training History\")\n",
    "    plt.show()\n",
    "    return vae\n",
    "\n",
    "\n",
    "vae = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbdpoIISsdjz"
   },
   "source": [
    "## 2D Latent Space\n",
    "\n",
    "We inspect the 2d latent space learned by our VAE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "xxwcRHmFqVoF",
    "outputId": "0eecaa4e-ae5d-49a8-8ef8-8c5a0016d833"
   },
   "outputs": [],
   "source": [
    "# Source: https://keras.io/examples/generative/vae\n",
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    fast_decoder = jax.jit(lambda model, z: model.decoder(z))\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = jax.nn.sigmoid(fast_decoder(vae, z_sample))\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(vae.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "sEukO2_CrnNv",
    "outputId": "6dd7c6fb-8457-4800-927b-b1e745e5702a"
   },
   "outputs": [],
   "source": [
    "# Source: https://keras.io/examples/generative/vae\n",
    "def plot_label_clusters(vae, data):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "\n",
    "    all_z_means = []\n",
    "    all_labels = []\n",
    "\n",
    "    fast_encoder = jax.jit(lambda model, data: model.encoder(data))\n",
    "\n",
    "    for batch in data:\n",
    "        batch = jax.tree_map(lambda x: x.numpy(), batch)\n",
    "        data, label = batch\n",
    "        z = fast_encoder(vae, data)\n",
    "        z_mean, _ = jnp.split(z, 2, axis=-1)\n",
    "        all_z_means.append(z_mean)\n",
    "        all_labels.append(label)\n",
    "\n",
    "    all_z_means = jnp.concatenate(all_z_means)\n",
    "    all_labels = jnp.concatenate(all_labels)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(all_z_means[:, 0], all_z_means[:, 1], c=all_labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "data_with_label = load_dataset(with_label=True).batch(batch_size, drop_remainder=True)\n",
    "plot_label_clusters(vae.eval(), data_with_label)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "LO8FzYhDrLdF"
   ],
   "name": "PAX's VAE example.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
